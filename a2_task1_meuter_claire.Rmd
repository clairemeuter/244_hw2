---
title: "task1_244_hw_1"
author: "Claire Meuter"
date: "2023-02-12"
output: 
  html_document:
    code_folding: hide
---

```{r setup, include=TRUE, warning = FALSE, message = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(reshape2)
library(ggplot2)
library(here)
library(AICcmodavg)
library(tidymodels)
library(kableExtra)
library(modelsummary)
library(patchwork)
```

## Section A: Introduction

This code wrangles, explores and compares two species of Florida Palmetto, *Serenoa repens* and *Sabal etonia*. Within this code, two binary logistic regression models for predicting palmetto species were created and compared. The more accurate model, Model 1, was evaluated for success of predicting palmetto species. 

Data for this code is sourced from the Archbold Biological Station in south-central Florida. 

**Citation:** Abrahamson, W.G. 2019. Survival, growth and biomass estimates of two dominant palmetto species of south-central Florida from 1981 - 2017, ongoing at 5-year intervals ver 1. Environmental Data Initiative. https://doi.org/10.6073/pasta/f2f96ec76fbbd4b9db431c79a770c4d5


## Section B: Data Wrangling and Data Visualization 
```{r}
palmetto <- read_csv(here("palmetto.csv")) %>% 
  select(species, height, length, width, green_lvs) %>% #keeping only the columns that I need
  mutate(species = as.factor(species), species = (fct_drop(species))) 


# %>% 
 # mutate(species = case_when(
 #   species == 1 ~ "serenoa_repens",
 #   species == 2 ~ "sabal_etonia"))
  

#Keeping this for notes if i need later
#palmetto <- read_csv(here("palmetto.csv")) %>% 
#  mutate(species = case_when(
 #   species == 1 ~ "serenoa_repens",
 #   species == 2 ~ "sabal_etonia"), species = as.factor(species)) #making species as.factor for regression 
  
```
b. A section containing 2 - 3 finalized (customized, suitable for a publication) data visualizations (with figure captions) in which you explore differences in height, canopy length, canopy width, and green leaves for the two species. If you prefer, combine the figures into a compound figure using {patchwork} or {cowplot}. Below your data visualizations, add a sentence or two with a takeaway from the plots, e.g., based on these plots, which predictor variables are more likely to help classify species correctly?

```{r}
# visualize differences in height, canopy length, canopy width, and green leaves 
width <- ggplot(data = palmetto) + geom_point(aes(x = width, y = height, color = species)) + labs(x = "Canopy width (cm)",
                                                                                                  y = "Canopy height (cm)") + 
  theme_minimal() + theme(legend.position = "none")
  


length <- ggplot(data = palmetto) + geom_point(aes(x = length, y = height, color = species)) + labs(x = " Canopy length (cm)",
                                                                                                  y = "Canopy height (cm)") + 
  theme_minimal()
 
green_lvs <- ggplot(data = palmetto) + geom_point(aes(x = green_lvs, y = height, color = species)) + labs(x = "Number of Green Leaves",
                                                                                                  y = "Canopy height (cm)") + 
  theme_minimal()
 


# histogram of green leaves by species
green_lvs2 <- ggplot(data = palmetto, aes(x = green_lvs)) +
  #boxes for s.etonia
  geom_histogram(data = subset(palmetto, species == 'Sabal etonia'), 
                 aes(fill = species),
                 binwidth = 1, boundary = -0.5, color = "black", alpha = 0.5) +
  #boxes for s.repens
  geom_histogram(data = subset(palmetto, species == 'Serenoa repens'), 
                 aes(fill = species),
                 binwidth = 1, boundary = -0.5,
                 color = 'black', alpha = 0.3) +
  #set colors and legend values
  scale_fill_manual(name = 'Species', 
                    values = c('darkgreen', 'lightgreen'),
                    labels = c('S. etonia', 'S. repens')) +
  #force origin to (0,0) and x-axis labels through 17
  scale_x_continuous(expand = c(0, 0), limits = c(0, 18), breaks=1:17) + 
  scale_y_continuous(expand = c(0, 0), limits = c(0, 2100)) +
  #axis labels
  labs(x = 'Number of green leaves',
       y = 'Count') +
  #set theme
  theme_minimal() 
 


width + length


```
Figure 1: Two scatterplots comparing the relationship between canopy height and width (left) and canopy height and length (right), between two palmetto species, *Sabel entonia* (red) and *Serenoa repens* (blue). A visual exploration of canopy height and width shows little variation between the *S. entonia* and *S. repens* species. A visual exploration of canopy height and length shows a slight variation between *S. entonia* and *S. repens* species, with *S. entonia* showing a slightly longer canopy length compared to *S. repens.* 
```{r}
green_lvs2
```
Figure 2: A histogram displaying the number of green leaves on *S. etonia* and *S. repens.* *S. etonia* observations are colored dark green, and *S. repens* observations are colored bright green. Where the count of green leaves overlaps, the graph is a combination green color.  

## Takeaway: 
Based on Figures 1 and 2, I suspect that number of green leaves and canopy length will be the most important in determining if a plant is *S. etonia* or *S. repens.* Canopy width shows little variation between the two species, but it could still be a useful model parameter, which I will explore in the next section. 

c. A section in which you perform binary logistic regression to determine the probability of a plant being either Serenoa repens or Sabal etonia based on several predictor variables.  Perform the analysis twice, using cross validation to compare two models:

#binary logistic regression to determine the probability of a plant being either Serenoa repens or Sabal etonia

#Log odds of plant type using plant height, canopy length, canopy width and green leaves as predictor variable.
```{r}

#First, I create a formula for model 1 with variables plant height, canopy length, canopy width and green leaves
f1 <- species ~ height + length + width + green_lvs
#Next, a formula for model 2 with variables plant height, canopy width and green leaves
f2 <- species ~ height + width + green_lvs

#Now I can run both of my models: 
mdl1 <- glm(f1, palmetto, family = "binomial")
mdl2 <- glm(f2, palmetto, family = "binomial")

# Get a tidy version w/ broom
mdl1_tidy <- tidy(mdl1)
mdl2_tidy <- tidy(mdl1)

#using AIC for initial exploration
AIC <- aictab(list(mdl1, mdl2),
              modnames = c("Model 1", "Model 2"))
#initally, model 1 is looking like the better fit, but now I'll do 10-fold cross validation to confirm 

```



## Tidymodels crossfold validation
```{r}

set.seed(444) ##setting seed for reproducibility purposes 


### use a workflow that bundles the logistic model and a formula
 palmetto_model <- logistic_reg() %>%
  set_engine('glm')
 
tidy_folds <- vfold_cv(palmetto, v = 10, repeats = 5) # With v = 10, I set the number of folds to ten, and repeat it 5 times

#Now I run model 1 
palm_tidy_wf1 <- workflow() %>%
  add_model(palmetto_model) %>%
  add_formula(f1)

palm_tidy_cv_f1 <- palm_tidy_wf1 %>%
  fit_resamples(tidy_folds)

### use functions from the tune package to extract useful metrics
metrics_md1 <- collect_metrics(palm_tidy_cv_f1)

### Repeating tidymodel method for model 2 

palm_tidy_wf2 <- workflow() %>%
  add_model(palmetto_model) %>%
  add_formula(f2)

palm_tidy_cv_f2 <- palm_tidy_wf2 %>%
  fit_resamples(tidy_folds)

### use functions from the tune package to extract useful metrics
metrics_md2 <- collect_metrics(palm_tidy_cv_f2)


# Format tables 

## model 1
metrics_md1 %>% 
  kable(caption = '**Table 1.** Cross validation metrics for Model 1.',
        col.names = c('Metric', 'Estimator', 'Mean',
                      'n', 'Standard error', 'Configuration')) %>% 
  kable_styling(full_width = FALSE,
                bootstrap_options = "hover",
                position = "left")
## model 2
metrics_md2 %>% 
  kable(caption = '**Table 2.** Cross validation metrics for Model 2.',
        col.names = c('Metric', 'Estimator', 'Mean',
                      'n', 'Standard error', 'Configuration')) %>% 
  kable_styling(full_width = FALSE,
                bootstrap_options = "hover",
                position = "left")

## End work flow 

```

By observing Tables 1 and 2, we can see that model 1 has a higher accuracy than model 2.

# Producing our final model

d. Train your selected model using the entire dataset, and create a finalized table (e.g., knitr::kable() and {kableExtra} functions) containing the binary logistic regression model results (at least coefficients, standard errors for the coefficients, and information for significance - consider using broom::tidy() to get you most of the way). 

```{r}
final_mdl <- glm(f1, palmetto, family = "binomial") #training model on all the data

#output my coefficients, standard errors for the coefficients, and information for significance
final_mdl_outputs <- tidy(final_mdl)

#put it into nice table 
final_mdl_outputs %>% 
  kable(caption = "Table 3. Coefficients of final model", 
        col.names = c("Variable", "Coefficient","Standard Error", "Statistic", "P-Value")) %>% 
  kable_styling(full_width = FALSE,
                bootstrap_options = "striped",
                position = "left")


```




```{r}
### This is copied from above, for reference
# blr_model <- logistic_reg() %>% ### also linear_reg, rand_forest, etc
#   set_engine('glm')
# 
# ### basic regression
# blr_tidyfit_f1 <- blr_model %>%
#   fit(f1, data = adelie_chinstrap)
# blr_tidyfit_f2 <- blr_model %>%
#   fit(f2, data = adelie_chinstrap)

#blr_f1_pred <- adelie_chinstrap %>%
#  mutate(predict(blr_tidyfit_f1, .),
#         predict(blr_tidyfit_f1, ., type = 'prob'))

#blr_f1_pred %>%
#  roc_curve(truth = species, .pred_Adelie) %>%
#  autoplot()

#blr_f1_pred %>%
#  roc_auc(truth = species, .pred_Adelie)

### Students repeat for blr_tidyfit_f2 and compare!
#blr_f2_pred <- adelie_chinstrap %>%
 # mutate(predict(blr_tidyfit_f2, .),
#         predict(blr_tidyfit_f2, ., type = 'prob'))

#blr_f2_pred %>%
#  roc_curve(truth = species, .pred_Adelie) %>%
#  autoplot()

#blr_f2_pred %>%
#  roc_auc(truth = species, .pred_Adelie)

```



e. A section that evaluates how successfully this model would “classify” a plant as the correct species, using a 50% cutoff (e.g. if the probability is >=50% that it is species A, then it would be classified as species A). Use broom::augment() to find the probabilities (instead of log-odds) for each plant in the original dataset, then add a column for which species your model would classify that plant as (using a 50% cutoff) based on the included predictor variables. The outcome should be a finalized table showing, for each species, how many plants in the original dataset would be correctly classified and how many were incorrectly classified by the model, as well as an additional column with “% correctly classified”. Add a table caption above the table, and a 1-2 sentence conclusion paragraph after.
To submit Task 1, knit to HTML. Ensure that all messages, warnings are hidden but all attached packages are visible (setup chunk included). Code should be available if we click on the Code button (use code folding in your R Markdown YAML header). Upload your file to GauchoSpace.


